# The name of your project
PROJECT_NAME=my-openeo-api

FLASK_ENV=production  # is this needed?

# Databases credentials
REDIS_PASSWORD=redispassword

POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# GDAL variables (do not change)
GDAL_VRT_ENABLE_PYTHON=TRUSTED_MODULES
GDAL_VRT_PYTHON_TRUSTED_MODULES=eodatareaders.pixel_functions.pixel_functions

# Apache Airflow
EXECUTOR=Celery
FERNET_KEY="46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho="
## Load DAGs example (default is false(n) - set to "y" if needed)
LOAD_EX=n
PLUGINS=./plugins
DAGS=./dags

# Volume paths
HOST_INPUT=/copernicus
CONTAINER_INPUT=/eodc/products/copernicus.eu
CONTAINER_OUTPUT=/data_out  # needs to be consitent with JOB_DATA var in jobs.env
LOG_DIR_AIRFLOW=/path/to/log/dir/airflow  # needs to be consitent with LOG_DIR var in api .env + /airflow

# URLs of Python and R UDF Services
OPENEO_PYTHON_UDF_URL=http://openeo-python-udf:5000/udf  # do not change if running the containerized one
OPENEO_R_UDF_URL=http://openeo-r-udf:5555/udf  # do not change if running the containerized one

# URL of CSW server
CSW_SERVER=http://pycsw:8000  # do not change if running the containerized one
